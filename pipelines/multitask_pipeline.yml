version: 1
description: ""
parallel: 1
properties:
  auto_dependency: true
  pipeline_type: "databricks_multitask"
jobs:
- csv_to_hive:
    job_parameters:
      source: "users1.csv"
      target: "users"
- "csv_to_hive_users2"
- hive_to_hive:
    job_parameters:
      source: "users"
      target: "users3"
- "hive_to_hive_users4"
- hive_to_hive:
    job_parameters:
      source: "users3"
      target: "users4"
- "hive_to_hive_users5"
- "csv_to_hive_users4"
computes:
- name: "compute_1"
  properties:
    spark_version: "9.1.x-scala2.12"
    driver_node_type_id: "Standard_DS3_v2"
    node_type_id: "Standard_DS3_v2"
    workers:
      num_workers: "1"
    spark_conf:
      conf1: "vaule1"
      conf2: "value2"
    spark_env_vars:
      env2: "value2"
      evn1: "value1"
    init_scripts:
    - "script1"
    cluster_tags:
      label1: "value1"
    retry_properties:
      max_retries: 2
      min_retry_interval_millis: 300000
- name: "compute_2"
  properties:
    spark_version: "9.1.x-scala2.12"
    driver_node_type_id: "Standard_DS3_v2"
    node_type_id: "Standard_DS3_v2"
    workers:
      autoscale:
        min_workers: "1"
        max_workers: "2"
folder: "/multitask_pipeline"
